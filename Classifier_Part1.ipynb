{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMzxj9magU5e"
   },
   "source": [
    "## AI Programming with Python Nanodegree: Image Classifier Project\n",
    "  - Do not make changes to the first 2 code cells, they are being used for setting up the `flowers` dataset and `cat_to_name.json`. Start writing code from third code cell onwards.\n",
    "  - To use this notebook: `File > Save a copy in Drive`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch\n",
    "pip install torchvision\n",
    "pip install collections\n",
    "pip install PIL\n",
    "pip install numpy \n",
    "pip install matplotlib\n",
    "pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5UZpVNNG17Q"
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zk1mSQqFlPwn"
   },
   "outputs": [],
   "source": [
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j4KEXNyymv3K"
   },
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rDpOnX7_ju3f"
   },
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "class_counts = Counter(train_data.targets)  # Count occurrences of each class\n",
    "num_classes = len(class_counts)\n",
    "# Compute class weights (inverse of frequency)\n",
    "class_weights = torch.tensor(\n",
    "    [1.0 / class_counts[c] for c in range(num_classes)], dtype=torch.float32).to(device)\n",
    "# Compute sample weights\n",
    "sample_weights = [1.0 / class_counts[c] for c in train_data.targets]\n",
    "# Create a sampler\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Use the sampler in the DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=sampler)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qiUBlDtlZ7-",
    "outputId": "22f1b516-2549-478f-cd5d-850a687406d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 108MB/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "\n",
    "# Load a pre-trained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze the parameters of the pre-trained model to prevent them from being updated during training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7nJQvvflmM-",
    "outputId": "b7786a67-eda5-4952-982a-d3b601477834"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=102, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a new classifier to replace the last fully connected layer of the model\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(2048, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 102),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# Replace the fully connected layer of the model with the new classifier\n",
    "model.fc = classifier\n",
    "\n",
    "# Define the loss function as Negative Log Likelihood Loss and class weights\n",
    "criterion = nn.NLLLoss(weight=class_weights)\n",
    "\n",
    "# Define the optimizer to update the parameters of the classifier\n",
    "learnrate = 0.001\n",
    "optimizer = optim.AdamW(model.fc.parameters(), lr=learnrate)\n",
    "\n",
    "# Move the model to the specified device (GPU or CPU)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4ZUMA7Hiloy5"
   },
   "outputs": [],
   "source": [
    "# Set the number of epochs for training\n",
    "epochs = 5\n",
    "step = 0\n",
    "running_loss = 0\n",
    "print_every = 50 # Print training progress every 50 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPprDEKFl5GE",
    "outputId": "ce6201f1-c16c-4ae5-8b23-644b0dfa89d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Train loss: 4.337.. Validation loss: 4.156.. Validation accuracy: 0.078\n",
      "Epoch 1/5.. Train loss: 3.216.. Validation loss: 2.868.. Validation accuracy: 0.280\n",
      "Epoch 2/5.. Train loss: 2.218.. Validation loss: 2.093.. Validation accuracy: 0.391\n",
      "Epoch 2/5.. Train loss: 1.673.. Validation loss: 1.607.. Validation accuracy: 0.512\n",
      "Epoch 3/5.. Train loss: 1.415.. Validation loss: 1.394.. Validation accuracy: 0.574\n",
      "Epoch 3/5.. Train loss: 1.237.. Validation loss: 1.263.. Validation accuracy: 0.623\n",
      "Epoch 4/5.. Train loss: 1.133.. Validation loss: 1.051.. Validation accuracy: 0.691\n",
      "Epoch 4/5.. Train loss: 1.008.. Validation loss: 0.931.. Validation accuracy: 0.731\n",
      "Epoch 5/5.. Train loss: 0.949.. Validation loss: 0.977.. Validation accuracy: 0.686\n",
      "Epoch 5/5.. Train loss: 0.898.. Validation loss: 0.800.. Validation accuracy: 0.769\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in trainloader:\n",
    "        step += 1\n",
    "\n",
    "        # Move images and labels to the specified device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients for the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the model output\n",
    "        logps = model(images)\n",
    "\n",
    "        # Calculate the loss using the predicted outputs and true labels\n",
    "        loss = criterion(logps, labels)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Evaluate the model every 'print_every' steps\n",
    "        if step % print_every == 0:\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            valid_loss = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            # Loop through the validation data\n",
    "            for images, labels in validloader:\n",
    "                # Move validation images and labels to the specified device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass: compute the model output for validation data\n",
    "                logps = model(images)\n",
    "\n",
    "                # Calculate the loss for validation data\n",
    "                loss = criterion(logps, labels)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                # Calculate probabilities from log probabilities\n",
    "                ps = torch.exp(logps)\n",
    "\n",
    "                # Get the top predicted class\n",
    "                top_ps, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "                # Check if the predicted class matches the true labels\n",
    "                equality = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "            # Print training and Validation statistics\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Validation loss: {valid_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Validation accuracy: {accuracy/len(validloader):.3f}\")\n",
    "\n",
    "            # Reset the running loss for the next print interval\n",
    "            running_loss = 0\n",
    "\n",
    "            # Set the model back to training mode\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2U7sJmQ6qHxn",
    "outputId": "e1cad222-58b8-4f1f-a073-7496887cf891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.92%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation for testing\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        # Move images and labels to the specified device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass: get model predictions\n",
    "        logps = model(images)\n",
    "\n",
    "        # Convert log probabilities to probabilities\n",
    "        ps = torch.exp(logps)\n",
    "\n",
    "        # Get the top predicted class\n",
    "        top_ps, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "        # Compare predictions to true labels\n",
    "        correct += (top_class.squeeze() == labels).sum().item()  # Count correct predictions\n",
    "        total += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YCs9FL8ETZyf"
   },
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint\n",
    "# Attach class_to_idx to the model\n",
    "model.class_to_idx = train_data.class_to_idx\n",
    "\n",
    "# Define the checkpoint dictionary\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),  # Model parameters\n",
    "    'class_to_idx': model.class_to_idx,  # Class mapping\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "    'epochs': epochs  # Number of epochs trained\n",
    "}\n",
    "\n",
    "# Save the checkpoint\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ABu9D-vyV_jr"
   },
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "\n",
    "    # Rebuild the model architecture\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Replace the classifier with the one from the checkpoint\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(2048, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 102),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    model.fc = classifier\n",
    "\n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Restore class-to-index mapping\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "\n",
    "    # Load optimizer state\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G2_0AbKtX0t_"
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    # Open the image\n",
    "    image = Image.open(image)\n",
    "\n",
    "    image.resize((256, 256)) # Resize\n",
    "\n",
    "    # Center Crop to 224x224\n",
    "    width, height = image.size\n",
    "    left = (width - 224) / 2\n",
    "    top = (height - 224) / 2\n",
    "    right = (width + 224) / 2\n",
    "    bottom = (height + 224) / 2\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert to NumPy array & normalize\n",
    "    np_image = np.array(image) / 255.0\n",
    "\n",
    "    # Normalize using mean and standard deviation per channel\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "\n",
    "    # Reorder dimensions (H, W, C) → (C, H, W)\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "\n",
    "    tensor_image = torch.tensor(np_image, dtype=torch.float32)\n",
    "\n",
    "    return tensor_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hQounNuIb2mc"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vF-bM07Udj5p"
   },
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "\n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "    # Process the image\n",
    "    image = process_image(image_path)\n",
    "\n",
    "    # Convert to a PyTorch tensor and add batch dimension\n",
    "    image = image.unsqueeze(0)  # Shape: (1, C, H, W)\n",
    "\n",
    "    # Ensure model is in evaluation mode & move image to same device as model\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Forward pass (disable gradient computation for efficiency)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Convert log probabilities to actual probabilities using softmax\n",
    "    probabilities = torch.exp(output)\n",
    "\n",
    "    # Get the top-K probabilities and their corresponding class indices\n",
    "    top_probs, top_indices = probabilities.topk(topk, dim=1)\n",
    "\n",
    "    # Convert tensors to lists\n",
    "    top_probs = top_probs.cpu().numpy().flatten()\n",
    "    top_indices = top_indices.cpu().numpy().flatten()\n",
    "\n",
    "    # Invert class_to_idx dictionary to map indices to actual class labels\n",
    "    idx_to_class = {idx: class_ for class_, idx in model.class_to_idx.items()}\n",
    "    top_classes = [idx_to_class[idx] for idx in top_indices]\n",
    "\n",
    "    return top_probs, top_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "_LfjJ-5_epyR",
    "outputId": "b218ff08-e007-4de4-80b6-fb55108819be"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load category-to-name mapping\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mcat_to_name.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     cat_to_name = \u001b[43mjson\u001b[49m.load(f)\n\u001b[32m      5\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33mrose.jpeg\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Load category-to-name mapping\n",
    "with open(\"cat_to_name.json\", \"r\") as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "image_path = \"rose.jpeg\"  # Replace with your image path\n",
    "\n",
    "# Get predictions\n",
    "probs, classes = predict(image_path, model, topk=5)\n",
    "\n",
    "# Convert class indices to flower names (Ensure class keys are strings)\n",
    "flower_names = [cat_to_name[str(class_)] for class_ in classes]\n",
    "\n",
    "# Process the image\n",
    "image = process_image(image_path)  # Ensure this returns a Torch tensor\n",
    "\n",
    "# Display the image\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6, 10), nrows=2)\n",
    "\n",
    "# Convert tensor to image format\n",
    "image = image.numpy().transpose((1, 2, 0))  # Convert from (C, H, W) → (H, W, C)\n",
    "\n",
    "ax1.imshow(image)  # Show image\n",
    "ax1.axis('off')  # Hide axes\n",
    "ax1.set_title(flower_names[0])  # Set title as the most probable class\n",
    "\n",
    "# Create horizontal bar chart for probabilities\n",
    "ax2.barh(flower_names, probs, color=\"blue\")\n",
    "ax2.invert_yaxis()  # Ensure highest probability is at the top\n",
    "ax2.set_xlabel(\"Probability\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "K7x4tB8rfrcy",
    "outputId": "305acfdf-3994-4e6f-8189-5dea9fe56176"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..2.64].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load category-to-name mapping\n",
    "with open(\"cat_to_name.json\", \"r\") as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "image_path = \"waterlily.jpeg\"  # Replace with your image path\n",
    "\n",
    "# Get predictions\n",
    "probs, classes = predict(image_path, model, topk=5)\n",
    "\n",
    "# Convert class indices to flower names (Ensure class keys are strings)\n",
    "flower_names = [cat_to_name[str(class_)] for class_ in classes]\n",
    "\n",
    "# Process the image\n",
    "image = process_image(image_path)  # Ensure this returns a Torch tensor\n",
    "\n",
    "# Display the image\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(6, 10), nrows=2)\n",
    "\n",
    "# Convert tensor to image format\n",
    "image = image.numpy().transpose((1, 2, 0))  # Convert from (C, H, W) → (H, W, C)\n",
    "\n",
    "ax1.imshow(image)  # Show image\n",
    "ax1.axis('off')  # Hide axes\n",
    "ax1.set_title(flower_names[0])  # Set title as the most probable class\n",
    "\n",
    "# Create horizontal bar chart for probabilities\n",
    "ax2.barh(flower_names, probs, color=\"blue\")\n",
    "ax2.invert_yaxis()  # Ensure highest probability is at the top\n",
    "ax2.set_xlabel(\"Probability\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWdDlxuM1YP4",
    "outputId": "4a45f314-abe8-492a-db86-1d8401f7208e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import argparse\n",
    "# Import necessary modules and functions\n",
    "from functions import build_model, train_model, load_data, save_checkpoint\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Train a neural network on flower data.\")\n",
    "    parser.add_argument(\"data_directory\", type=str, help=\"Path to the dataset\")\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"saved_models\", help=\"Directory to save checkpoints\")\n",
    "    parser.add_argument(\"--arch\", type=str, default=\"resnet50\", help=\"Model architecture\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument(\"--hidden_layer_1_units\", type=int, default=256, help=\"Number of neurons/units in first hidden layer\")\n",
    "    parser.add_argument(\"--hidden_layer_2_units\", type=int, default=128, help=\"Number of neurons/units in second hidden layer\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5, help=\"Number of epochs\")\n",
    "    parser.add_argument(\"--gpu\", action=\"store_true\", help=\"Use GPU for training\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load the data\n",
    "    trainloader, validloader, testloader = load_data(args.data_directory)\n",
    "    # Determine device (use GPU if specified and available)\n",
    "    device = torch.device(\"cuda\" if args.gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    # Build the model\n",
    "    model = build_model(args.arch, args.hidden_layer_1_units, args.hidden_layer_2_units)\n",
    "    model.to(device)  # Move model to GPU/CPU\n",
    "    # Train the model\n",
    "    optimizer = train_model(model, trainloader, validloader, args.epochs, args.learning_rate, args.gpu)\n",
    "    # Save the checkpoint\n",
    "    save_checkpoint(model, optimizer, args.epochs, trainloader.dataset.class_to_idx)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWaCUcmI9tT-",
    "outputId": "2e08b465-3ec2-48e6-834b-f76e0f40c41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict.py\n",
    "import argparse\n",
    "# Import necessary modules and functions\n",
    "from functions import load_checkpoint, process_image, predict\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Predict flower name from an image using a trained network.\")\n",
    "    parser.add_argument(\"input\", type=str, help=\"Path to the input image\")\n",
    "    parser.add_argument(\"checkpoint\", type=str, help=\"Path to the model checkpoint\")\n",
    "    parser.add_argument(\"--top_k\", type=int, default=1, help=\"Return top K most likely classes\")\n",
    "    parser.add_argument(\"--category_names\", type=str, help=\"Path to JSON file mapping categories to real names\")\n",
    "    parser.add_argument(\"--gpu\", action=\"store_true\", help=\"Use GPU for inference\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load the model from checkpoint\n",
    "    model = load_checkpoint(args.checkpoint)\n",
    "\n",
    "    # Process the image\n",
    "    image = process_image(args.input)\n",
    "    # Predict the class\n",
    "    probs, classes = predict(args.input, model, args.top_k, args.gpu)\n",
    "\n",
    "    # Optionally map categories to real names\n",
    "    if args.category_names:\n",
    "        import json\n",
    "        with open(args.category_names, 'r') as f:\n",
    "            cat_to_name = json.load(f)\n",
    "        classes = [cat_to_name.get(str(cls), cls) for cls in classes]\n",
    "\n",
    "    print(\"Predicted Classes:\", classes)\n",
    "    print(\"Probabilities:\", probs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9AsIDx0DPE5",
    "outputId": "bf2b3c0d-9dae-4586-d0fb-a1084527345e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functions.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import optimizer\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_data(data_dir):\n",
    "  train_dir = data_dir + '/train'\n",
    "  valid_dir = data_dir + '/valid'\n",
    "  test_dir = data_dir + '/test'\n",
    "\n",
    "  # Define your transforms for the training, validation, and testing sets\n",
    "  train_transforms = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "  valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "  test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "  # Load the datasets with ImageFolder\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "  valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "  # Using the image datasets and the trainforms, define the dataloaders\n",
    "  class_counts = Counter(train_data.targets)  # Count occurrences of each class\n",
    "  num_classes = len(class_counts)\n",
    "  # Compute class weights (inverse of frequency)\n",
    "  class_weights = torch.tensor(\n",
    "      [1.0 / class_counts[c] for c in range(num_classes)], dtype=torch.float32).to(device)\n",
    "  # Compute sample weights\n",
    "  sample_weights = [1.0 / class_counts[c] for c in train_data.targets]\n",
    "  # Create a sampler\n",
    "  sampler = torch.utils.data.WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "  # Use the sampler in the DataLoader\n",
    "  trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, sampler=sampler)\n",
    "  validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n",
    "  testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "\n",
    "  return trainloader, validloader, testloader\n",
    "\n",
    "def build_model(architecture, hidden_layer_1_units, hidden_layer_2_units):\n",
    "  # Build your network\n",
    "  # Load a pre-trained ResNet50 model\n",
    "  model = models.resnet50(pretrained=True)\n",
    "\n",
    "  # Freeze the parameters of the pre-trained model to prevent them from being updated during training\n",
    "  for param in model.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  # Define a new classifier to replace the last fully connected layer of the model\n",
    "  classifier = nn.Sequential(\n",
    "    nn.Linear(2048, hidden_layer_1_units),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_1_units, hidden_layer_2_units),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_2_units, 102),\n",
    "    nn.LogSoftmax(dim=1)\n",
    "  )\n",
    "\n",
    "  # Replace the fully connected layer of the model with the new classifier\n",
    "  model.fc = classifier\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(model, trainloader, validloader, epochs, learning_rate, gpu):\n",
    "  # Set the number of epochs for training\n",
    "  step = 0\n",
    "  running_loss = 0\n",
    "  print_every = 50\n",
    "  criterion = nn.NLLLoss()\n",
    "  optimizer = optim.AdamW(model.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Move the model to the specified device (GPU or CPU)\n",
    "  model.to(device)# Print training progress every 50 steps\n",
    "  # Training loop\n",
    "  for epoch in range(epochs):\n",
    "      for images, labels in trainloader:\n",
    "          step += 1\n",
    "\n",
    "          # Move images and labels to the specified device\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "          # Zero the gradients for the optimizer\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Forward pass: compute the model output\n",
    "          logps = model(images)\n",
    "\n",
    "          # Calculate the loss using the predicted outputs and true labels\n",
    "          loss = criterion(logps, labels)\n",
    "\n",
    "          # Backward pass: compute gradients\n",
    "          loss.backward()\n",
    "\n",
    "          # Update the model parameters\n",
    "          optimizer.step()\n",
    "\n",
    "          # Accumulate the running loss\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          # Evaluate the model every 'print_every' steps\n",
    "          if step % print_every == 0:\n",
    "              model.eval()  # Set the model to evaluation mode\n",
    "              valid_loss = 0\n",
    "              accuracy = 0\n",
    "\n",
    "              # Loop through the validation data\n",
    "              for images, labels in validloader:\n",
    "                  # Move validation images and labels to the specified device\n",
    "                  images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                  # Forward pass: compute the model output for validation data\n",
    "                  logps = model(images)\n",
    "\n",
    "                  # Calculate the loss for validation data\n",
    "                  loss = criterion(logps, labels)\n",
    "                  valid_loss += loss.item()\n",
    "\n",
    "                  # Calculate probabilities from log probabilities\n",
    "                  ps = torch.exp(logps)\n",
    "\n",
    "                  # Get the top predicted class\n",
    "                  top_ps, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "                  # Check if the predicted class matches the true labels\n",
    "                  equality = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "                  # Calculate accuracy\n",
    "                  accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "              # Print training and Validation statistics\n",
    "              print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                    f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                    f\"Validation loss: {valid_loss/len(validloader):.3f}.. \"\n",
    "                    f\"Validation accuracy: {accuracy/len(validloader):.3f}\")\n",
    "\n",
    "              # Reset the running loss for the next print interval\n",
    "              running_loss = 0\n",
    "\n",
    "              # Set the model back to training mode\n",
    "              model.train()\n",
    "  return optimizer\n",
    "# Save the checkpoint\n",
    "# Attach class_to_idx to the model\n",
    "def save_checkpoint(model, optimizer, epochs, class_to_idx):\n",
    "    # Define the checkpoint dictionary\n",
    "    checkpoint = {\n",
    "      'model_state_dict': model.state_dict(),  # Model parameters\n",
    "      'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "      'epochs': epochs,  # Number of epochs trained\n",
    "      'class_to_idx': class_to_idx  # Save class mapping\n",
    "      }\n",
    "\n",
    "    # Save the checkpoint\n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "# Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "\n",
    "    # Rebuild the model architecture\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Replace the classifier with the one from the checkpoint\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(2048, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 102),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "    model.fc = classifier\n",
    "\n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Restore class-to-index mapping\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "\n",
    "    # Load optimizer state\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "\n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "    # Open the image\n",
    "    image = Image.open(image)\n",
    "\n",
    "    image.resize((256, 256)) # Resize\n",
    "\n",
    "    # Center Crop to 224x224\n",
    "    width, height = image.size\n",
    "    left = (width - 224) / 2\n",
    "    top = (height - 224) / 2\n",
    "    right = (width + 224) / 2\n",
    "    bottom = (height + 224) / 2\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert to NumPy array & normalize\n",
    "    np_image = np.array(image) / 255.0\n",
    "\n",
    "    # Normalize using mean and standard deviation per channel\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "\n",
    "    # Reorder dimensions (H, W, C) → (C, H, W)\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "\n",
    "    tensor_image = torch.tensor(np_image, dtype=torch.float32)\n",
    "\n",
    "    return tensor_image\n",
    "\n",
    "def predict(image_path, model, topk, gpu):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    # Implement the code to predict the class from an image file\n",
    "    # Process the image\n",
    "    image = process_image(image_path)\n",
    "\n",
    "    # Convert to a PyTorch tensor and add batch dimension\n",
    "    image = image.unsqueeze(0)  # Shape: (1, C, H, W)\n",
    "\n",
    "    # Ensure model is in evaluation mode & move image to same device as model\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Forward pass (disable gradient computation for efficiency)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    # Convert log probabilities to actual probabilities using softmax\n",
    "    probabilities = torch.exp(output)\n",
    "\n",
    "    # Get the top-K probabilities and their corresponding class indices\n",
    "    top_probs, top_indices = probabilities.topk(topk, dim=1)\n",
    "\n",
    "    # Convert tensors to lists\n",
    "    top_probs = top_probs.cpu().numpy().flatten()\n",
    "    top_indices = top_indices.cpu().numpy().flatten()\n",
    "\n",
    "    # Invert class_to_idx dictionary to map indices to actual class labels\n",
    "    idx_to_class = {idx: class_ for class_, idx in model.class_to_idx.items()}\n",
    "    top_classes = [idx_to_class[idx] for idx in top_indices]\n",
    "\n",
    "    return top_probs, top_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5bTb_P397BO",
    "outputId": "445987d5-6be5-473a-a85b-8fcdf9bb9704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/5.. Train loss: 4.388.. Validation loss: 3.852.. Validation accuracy: 0.144\n",
      "Epoch 1/5.. Train loss: 3.225.. Validation loss: 2.364.. Validation accuracy: 0.438\n",
      "Epoch 2/5.. Train loss: 2.117.. Validation loss: 1.528.. Validation accuracy: 0.599\n",
      "Epoch 2/5.. Train loss: 1.631.. Validation loss: 1.285.. Validation accuracy: 0.630\n",
      "Epoch 3/5.. Train loss: 1.348.. Validation loss: 1.068.. Validation accuracy: 0.718\n",
      "Epoch 3/5.. Train loss: 1.149.. Validation loss: 0.894.. Validation accuracy: 0.756\n",
      "Epoch 4/5.. Train loss: 1.068.. Validation loss: 0.762.. Validation accuracy: 0.799\n",
      "Epoch 4/5.. Train loss: 0.971.. Validation loss: 0.707.. Validation accuracy: 0.806\n",
      "Epoch 5/5.. Train loss: 0.926.. Validation loss: 0.708.. Validation accuracy: 0.798\n",
      "Epoch 5/5.. Train loss: 0.843.. Validation loss: 0.630.. Validation accuracy: 0.818\n"
     ]
    }
   ],
   "source": [
    "!python train.py flowers --save_dir saved_models --arch \"resnet50\" --learning_rate 0.001 --hidden_layer_1_units 256 --hidden_layer_2_units 128 --epochs 5 --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFG2iuE7bcPd",
    "outputId": "add81fac-da02-4c15-b0cb-5bd554021691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/functions.py:179: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filepath)\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Predicted Classes: ['lotus lotus', 'water lily', 'japanese anemone']\n",
      "Probabilities: [0.5999533  0.1836624  0.08037149]\n"
     ]
    }
   ],
   "source": [
    "!python predict.py lotus.jpeg checkpoint.pth --top_k 3 --category_names cat_to_name.json --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykeaYhVmgmHz",
    "outputId": "570e2554-b82e-4e90-d7a3-f557502bde11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Classes: ['water lily', 'lotus lotus', 'frangipani']\n",
      "Probabilities: [0.9556091  0.02045408 0.01706157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fareedah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fareedah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "!python predict.py waterlily.jpeg checkpoint.pth --top_k 3 --category_names cat_to_name.json --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Classes: ['californian poppy', 'buttercup', 'sunflower']\n",
      "Probabilities: [0.19125363 0.1412222  0.12423483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fareedah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fareedah\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!python predict.py sunflower.jpg checkpoint.pth --top_k 3 --category_names cat_to_name.json --gpu"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
